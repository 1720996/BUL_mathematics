\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{url,amsmath,graphicx,amssymb,booktabs}
\usepackage[top=1.5cm, bottom=1.5cm, left=2.5cm, right=2.5cm]{geometry}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}

\title{MA3614 - Complex Variable Methods and Applications}
\author{1720996}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\section{Introduction and Revision}
\subsection{Some definitions and notations}
\begin{definition}
    An ordinary differential equation (ODE) is an equation involving one or more derivatives of an unknown function of one variable.
\end{definition}
\begin{definition}
    The order of an ODE is the order of the highest derivative of the unknown function in the equation.
\end{definition}
\begin{definition}
    Suppose that $y$ is the unknown function and $x$ is the independent variable. Then the $ODE$ is linear (of order $m\in \mathbb{N}$) if one can represent it in the form:
    \begin{equation}
        a_m(x)\frac{d^m y}{dx^m} + a_{m-1}(x)\frac{d^{m-1}}{dx^{m-1}} + \ldots + a_1(x)\frac{dy}{dx}+a_)(x) y=f(x). \label{eq:order}
    \end{equation}
    Any other type of ODE is nonlinear.
\end{definition}
\begin{definition}
    A linear ODE is homogeneous if $f(x)\equiv 0$ in eq.~(\ref{eq:order}).
\end{definition}

\begin{table}[h]
\begin{tabular}{|c|c|c|c|c|}
\hline
   & ODE & Order & Linear & Homogeneous \\ \hline
 $1$ & $ 5\frac{d^2 y}{dx^2} - 6\frac{dy}{dx} + y = xe^x $ & $2$ & Yes & No \\ 
 $2$ & $xy\frac{dy}{dx} + \frac{d^4 y}{dx^4} = \sin{x}$ & $4$ & No & No \\
 $3$ & $x^2\frac{d^2 y}{dx^2} + x\frac{dy}{dx} + (x^2 - 1)y = 0$ & $2$ & Yes & Yes \\
 $4$ & $\left( y+\frac{d^3 y}{dx^3} \right)^2 + \frac{dy}{dx} = ye^x$ & $3$ & No & No \\
 $5$ & $x^2\frac{d^2 y}{dx^2}+y\cos{x} = x^2$ & $2$ & Yes & No \\ \hline
\end{tabular}
\end{table}
\subsection{First-order ODEs}
We can write a general form for a first-order ODE as
\begin{equation}
    F(x,y,y^\prime) = 0,\nonumber
\end{equation}
where $F$ is a given function of three variables.
\subsubsection{Direct Integration}
This is appropriate for ODEs of the type:
\begin{equation}
    \frac{dy}{dx} = f(x).
\end{equation}

\subsubsection{The method of seperation of variables}
This method is appropriate for the ODEs of the type:
\begin{equation}
    \frac{dy}{dx} = p(x)q(y),
\end{equation}
where $p(x)$ and $q(x)$ are known functions.

\subsubsection{Integrating factor method}
General first order linear ODEs of the form:
\begin{equation}
    \frac{dy}{dx} + P(x)y = Q(x)
\end{equation}
can be solved using an integrating factor $\lambda$, where
\begin{equation}
    \lambda(x) = e^{\int P(x)\,dx}.
\end{equation}
Hence,
\begin{equation}
    y(x) = \frac{1}{\lambda(x)}\int \lambda(x)Q(x)\,dx+\frac{C}{\lambda(x)}.
\end{equation}

\section{Second order linear ODEs}
\subsection{Some theory}
A second order linear ODE has the general form
\begin{equation}
    a_2(x)y^{\prime\prime} + a_1(x)y^\prime + a_0(x)y = f(x).
\end{equation}
\begin{theorem}
    Consider the IVP
    \begin{equation}
        y^{\prime\prime} + \tilde{a}_1(x)y^\prime + \tilde{a}_0(x)y = 0,\quad y(x_0)=\alpha,\quad y^\prime(x_0)=\beta
    \end{equation}
    where $\tilde{a}_1(x)$, $\tilde{a}_0$ are continuous on an open interval, say $(a,b)$, containing $x_0$. There is exactly one solution $y=\phi(x)$ to the IVP and the solution exists throughout $(a,b)$.
\end{theorem}

\subsection{Second order linear ODEs with constant coefficients}
This is in the form:
\begin{equation}
    a_2\frac{d^2 y}{dx^2} + a_1\frac{dy}{dx} + a_0 y = f(x)
\end{equation}
where $a_0,\,a_1,\,a_2$ are constants.

\subsubsection{The homogeneous case}

\begin{itemize}
    \item \textbf{Real distinct roots: }Let the roots be $m_1$ and $m_2$ where $m_1\neq m_2$. Then $y_1 = e^{m_1 x}$ and $y_2 = e^{m_2 x}$ are both solutions. The general solution is the linear combination:
    \begin{equation}
        y = Ae^{m1_x} + Be^{m_2 x}.
    \end{equation}
    \item \textbf{Real repeated roots: }Let the roots be equal so that $m_1=m_2$. Then one solution is $y_1 = e^{m_1 x}$ and the second is $y=xe^{m_1}$. Thus the general solution is:
    \begin{equation}
        y = (Ax + B)e^{m_1 x}.
    \end{equation}
    \item \textbf{Complex roots: }Let the roots be complex such that $m_1 = \alpha+i\beta$ and $m_2 = \alpha - i\beta$ where $\alpha$ and $\beta$ are real numbers. There are two distinct solutions to the ODE, namely $y_1 = e^{(\alpha + i\beta)x}$ and $y_2 = e^{(\alpha - i\beta)x}$. The general solutions is a linear combination which may be written as:
    \begin{equation}
        y = e^{\alpha x}(Ae^{i\beta x}+Be^{-i\beta x}).
    \end{equation}
    Equivalently:
    \begin{equation}
        y = e^{\alpha x}[C\cos{(\beta x)}+D\sin{(\beta x)}],
    \end{equation}
    where the two arbitrary constants are $C=A+B$ and $D = i(A+B)$.
\end{itemize}

\subsubsection{The particular integral}
Look through examples.

\subsection{Euler equations (homogeneous)}
This class of ODE has the general form:
\begin{equation}
    ax^2\frac{d^2 y}{dx^2} + bx\frac{dy}{dx} + cy = f(x)
\end{equation}
where $a,\, b$ are constants. 
\begin{itemize}
    \item \textbf{Real distinct roots: }Let the roots be $m_1$ and $m_2$ where $m_1\neq m_2$. Then $y_1 = x^{m_1}$ and $y_2 = x^{m_2}$ are both solutions. The general solution is the following:
    \begin{equation}
        y = Ae^{\frac{m_1}{2}\ln{x^2}} + Be^{\frac{m_2}{2}\ln{x^2}},\quad x<0\,\text{ or }\, x>0.
    \end{equation}
    \item \textbf{Real repeated roots: }Let the roots be equal so that $m_1=m_2$. The one solution to the ODE is $y_1 = x^{m_1}$ and the second is $y = x^{m_1}\ln{x}$. Thus, the general solution is:
    \begin{equation}
        y = (\tilde{A}\ln{x^2}+B)e^{\frac{m_1}{2}\ln{x^2}},\quad x<0\,\text{ or }\,x>0,
    \end{equation}
    where $\tilde{A} = A/2$ is arbitrary.
    \item \textbf{Complex roots: }Let the roots be complex such that $m_1 = \alpha+i\beta$ and $m_2 = \alpha - i\beta$ where $\alpha$ and $\beta$ are real numbers. There are two distinct solutions to the ODE, namely $y_1 = x^{(\alpha + i\beta)}$ and $y_2 = x^{(\alpha - i\beta)}$. The general solutions is a linear combination which may be written as:
    \begin{equation}
        y = e^{\frac{\alpha}{2}\ln{x^2}}\left[ C\cos{\left( \frac{\beta}{2}\ln{x^2} \right)} + D\sin{\left( \frac{\beta}{2}\ln{x^2} \right)} \right],\quad x<0\,\text{ or }\, x>0.
    \end{equation}
\end{itemize}
\textbf{Note: }For an Euler equation of the form
\begin{equation}
    a(x-x_0)^2\frac{d^2 y}{dx^2} + b(x-x_0)\frac{dy}{dx} + cy = 0,
\end{equation}
the solution is exactly the same except that we look for solutions of the form $y = (x-x_0)^m$.

\subsection{Linearly independent solutions}
\begin{theorem}
    If $y_1$ and $y_2$ are two solutions of the differential equation
    \begin{equation}
        y^{\prime\prime}+\tilde{a}_1(x)y^\prime + \tilde{a}_0(x)y = 0, \label{eq:LIS}
    \end{equation}
    then the linear combination
    \begin{equation}
        y = Ay_1 + By_2 \label{eq:lincom}
    \end{equation}
    is also a solution for any values of $A$ and $B$.
\end{theorem}
\begin{definition}
    Two solutions, $y_1$ and $y_2$, of eq.~(\ref{eq:LIS}) form a fundamental set of solutions if every solution of eq.~(\ref{eq:LIS}) can be expressed as a linear combination of the form eq.~(\ref{eq:lincom}). 
\end{definition}
\begin{definition}
    Two functions, $y_1(x)$ and $y_2(x)$ are said to be linearly independent on an interval $(a,b)$ if the only solution to $Ay_1(x)+By_1(x) = 0$ on $(a,b)$ is $A=B=0$. 
\end{definition}
\begin{theorem}
    Let $\tilde{a}_1(x)$ and $\tilde{a}_0(x)$ be continuous on $(a,b)$ and let $y_1$ and $y_2$ be two solutions of the differential eq.~(\ref{eq:LIS}). Then the following three statements are equivalent:
    \begin{enumerate}
        \item $y_1$ and $y_2$ are a fundamental set;
        \item $y_1$ and $y_2$ are linearly independent;
        \item the Wronskian $W(y_1,y_2;x_0)$ does not vanish at any interior point $x_0$ of $(a,b)$ (it could be, however, vanish as $x_0\to a$ or $x_0\to b$).
    \end{enumerate}
\end{theorem}
\begin{theorem}
    Let $\tilde{a}_1(x)$ and $\tilde{a}_0(x)$ be continuous on $(a,b)$, then the Wronskian of the differential eq.~(\ref{eq:LIS}) is given by
    \begin{equation}
        W=C\exp \left\{ -\int\tilde{a}_1(x)\, dx \right\}.
    \end{equation}
\end{theorem}

\subsection{Reduction of order}
Look through examples.

\subsection{Normal Form ODEs}
Look through examples.

\subsection{ODEs with singular points}
Consider the general seconds order linear ODE
\begin{equation}
    a_2(x)y^{\prime\prime}+a_1(x)y^\prime + a_0(x)y = f(x).
\end{equation}
The solution of such ODEs in an interval, say $(a,b)$, is closely linked to the behaviour of $a_2(x)$ in that interval.
\begin{itemize}
    \item A point $x_0\in(a,b)$ such that $a_2(x_0)\neq 0$ is called an ordinary point.
    \item A point $x_0\in(a,b)$ such that $a_2(x_0) = 0$ but $a_1(x_0)\neq 0$ and/or $a_0(x_0)\neq 0$ is called a singular point.
\end{itemize}
A singular point is a regular singular point if
\begin{equation}
    \lim_{x\to x_0}(x-x_0)\frac{a_1(x)}{a_2(x)}\quad \text{and}\quad \lim_{x\to x_0}(x-x_0)^2\frac{a_0(x)}{a_2(x)}
\end{equation}
both exist. A singular point that does not satisfy this is called an irregular singular point.

\section{Perturbation techniques}
\subsection{Regular Perturbation}
Use examples.

\subsection{The WKB method}
Use examples.

\section{Sturm-Liouville theory}
\subsection{Introduction to eigenvalues and eigenfunctions}
Use examples.

\subsection{Sturm-Liouville eigenvalue problems}
Use examples.

\begin{theorem}
    All the eigenvalues of the Sturm-Liouville problem are real.
\end{theorem}

\begin{theorem}
    If $\phi_1(x)$ and $\phi_2(x)$ are two eigenfunctions of the Sturm-Liouville problem with corresponding eigenfunctions $\lambda_1$ and $\lambda_2$, $\lambda_1\neq \lambda_2$, then
    \begin{equation}
        \int_0^1 r(x)\phi_1 \phi_2\,dx=0.
    \end{equation}
\end{theorem}
\begin{theorem}
    The eigenvalues of the Sturm-Liouville problem are all simple. That is, to each eigenvalue there corresponds only one linearly independent eigenfunction. Further, the eigenvalues form an infinite sequence and can be ordered according to increasing magnitude so that:
    \begin{equation}
        \lambda_1<\lambda_2<\lambda_3<\lambda_4<\ldots<\lambda_n<\ldots.
    \end{equation}
    Moreover, $\lambda_n\to\infty$ as $n\to\infty$.
\end{theorem}

\section{PDEs}
\subsection{Some definitions}
\begin{definition}
    Consider a dependent variable $\phi$ which is a function of two (or more) independent variables, e.g. $\phi=\phi(x,y)$. A partial differential equation (PDE) relates partial derivatives of $\phi$ (with respect to $x$ and $y$) to $x,\,y$ and $\phi$.
\end{definition}
\begin{definition}
    The order of a PDE is the order of its highest derivative. Thus,
    \begin{equation}
        \frac{\partial \phi}{\partial x} + \gamma(x)\frac{\partial \phi}{\partial y} = f(x),
    \end{equation}
    where $\gamma$ and $f$ are functions of $x$, is a first order PDE, whereas
    \begin{equation}
        \frac{\partial \phi}{\partial x}+ x\frac{\partial^4 \phi}{\partial y^4} = x^3
    \end{equation}
    is a fourth order PDE.
\end{definition}
\begin{definition}
    A PDE for $\phi=\phi(x,y)$ is called linear if it is linear in $\phi$. Thus,
    \begin{equation}
        \phi_x + y\phi_{xyy} = 0,\quad\text{is linear, but}\quad \phi_x + y\phi_{xyy} + \phi^2 = 0\quad\text{is not.}
    \end{equation}
\end{definition}
\begin{definition}
    A PDE is quasi-linear if all the highest derivatives appear only to the power one. They can, however, be multiplied by functions containing $x$, $y$ or lower derivatives of $\phi$. \\
    A PDE is fully non-linear if none of the above conditions apply.
\end{definition}



\section{First order quasi-linear PDEs}
The most general $1$st order quasi-linear PDE has the form
\begin{equation}
    a(x,y,\phi)\frac{\partial \phi}{\partial x}(x,y) + b(x,y,\phi)\frac{\partial \phi}{\partial y}(x,y) = c(x,y,\phi). \label{eq:quasi_case1}
\end{equation}


\subsection{$c(x,y,\phi)=0$}
The characteristic curves of a PDE equivalent to eq.~(\ref{eq:quasi_case1}) are given by:
\begin{equation}
    \frac{dy}{dx} = \frac{-\xi_x(x,y)}{\xi_y(x,y)} = \frac{b(x,y)}{a(x,y)},
\end{equation}
or equivalently,
\begin{equation}
    \frac{dx}{a(x,y)} = \frac{dy}{b(x,y)},
\end{equation}
where $\xi$ is the tangent to the curves. You can then integrate to find the solution to the $PDE$, then re-express in terms of $x$ and $y$.

\subsection{$c(x,y,\phi)\neq0$ and $a,\,b$ are independent of $\phi$}\label{sec:quasi_case2}
This PDE has the form
\begin{equation}
    a(x,y)\phi_x + b(x,y)\phi_y = c(x,y,\phi),
\end{equation}
which can be written as
\begin{equation}
    (a(x,y),\,b(x,y))\cdot\nabla\phi = c(x,y,\phi).
\end{equation}
To solve, introduce a unit vector $\underline{\hat{s}}$ in the direction of $(a,\,b)$ so that
\begin{equation}
    \underline{\hat{s}} = \frac{(a,\,b)}{\sqrt{a^2+b^2}}.
\end{equation}
Express this as a directional derivative:
\begin{equation}
    \underline{\hat{s}}\cdot\nabla\phi = \frac{c}{\sqrt{a^2+b^2}}.
\end{equation}
Use the chain rule to express:
\begin{equation}
    \frac{\partial \phi}{\partial s} = \frac{\partial \phi}{\partial x}\frac{dx}{ds} + \frac{\partial \phi}{\partial y}\frac{dy}{ds}.
\end{equation}
We now find that
\begin{equation}
     \underline{\hat{s}}\cdot\nabla\phi =  \frac{\partial \phi}{\partial s} = \frac{c}{\sqrt{a^2+b^2}},
\end{equation}
giving us a first order PDE. We now integrate to find
\begin{align}
    \phi(s,\xi) &= \int \frac{c}{\sqrt{a^2+b^2}}\,ds + f(\xi), \\
    &= P(s,\xi) + f(\xi) \nonumber
\end{align}
where $P(s,\xi)$ is a particular integral and $f(\xi)$ an arbitrary function which is chosen that the boundary conditions are satisfied.\\
Finally, re-express this solution in terms of $x$ and $y$.
\begin{theorem}
    The general solution of the first order PDE 
    \begin{equation}
        a(x,y)\frac{\partial\phi}{\partial x} + b(x,y)\frac{\partial\phi}{\partial y} = c(x,y,\phi_)
    \end{equation}
    is $U(\xi,\eta) = 0$ where $\xi(x,y,\phi) = \alpha$, $\eta(x,y,\phi) = \beta$, $\alpha,\,\beta$ constant, are the solutions to the characteristic equation:
    \begin{equation}
        \frac{dx}{a(x,y)} = \frac{dy}{b(x,y)} = \frac{d\phi}{c(x,y)}
    \end{equation}
    and $U$ is an arbitrary differentiable function of $\xi$ and $\eta$.
\end{theorem}
This also works when $a = a(x,y,\phi$ and/or $b = b(x,y,\phi)$.

\subsection{$c(x,y,\theta)\neq0$ and $a$ and/or $b$ depend on $\phi$}
See above approach from~\ref{sec:quasi_case2} where 
\begin{equation}
    \frac{dx}{a(x,y)} = \frac{dy}{b(x,y)} = \frac{d\phi}{c(x,y)}.
\end{equation}



\section{Second Order Linear PDEs}
In $2D$ a second order linear PDE has the general form
\begin{equation}
    A\phi_{xx} + B\phi_{xy} + C\phi_{yy} + D\phi_x + E\phi_y + F\phi = G,\label{eq:SecondOrderGeneral}
\end{equation}
where $A,\,B,\,C,\ldots,\,G$ are functions of $x$ and $y$ \textbf{only}.

\subsection{Change of independent variables and reduction of the canonical form}
Using the notation in eq.~(\ref{eq:SecondOrderGeneral}):
\begin{equation}
    \frac{\xi_x}{\xi_y} = \frac{dy}{dx} = \frac{B \pm \sqrt{\Delta}}{2A},
\end{equation}
where 
\begin{equation}
    \Delta = B^2 -4AC.
\end{equation}
\begin{definition}
    The two equations
    \begin{equation}
        \frac{dy}{dx} = \frac{1}{2A} (B+\sqrt{\Delta}),\quad\text{and}\quad \frac{dy}{dx} = \frac{1}{2A}(B-\sqrt{\Delta})\label{eq:second_char}
    \end{equation}
    are called the characteristic equations of eq.~(\ref{eq:SecondOrderGeneral}), defining two families of characteristic curves.
\end{definition}
\begin{definition}
    The second order PDE (\ref{eq:SecondOrderGeneral}) is said to be hyperbolic if $\Delta>0$, parabolic if $\Delta = 0$, and elliptic if $\Delta<0$.
\end{definition}


\subsection{Hyperbolic PDEs ($\Delta > 0$)}
We denote the solutions by
\begin{equation}
    \xi(x,y) = \alpha,\quad\eta(x,y)=\beta,
\end{equation}
and use $\xi$ and $\eta$ as a new set of independent variables.\\
Solve for the characteristic equations from~(\ref{eq:second_char}) and define $\xi$ and $\eta$. You then find, in terms of $x$ and $y$ that we have:
\begin{equation}
    \phi(x,y) = F(\xi(x,y)) + G(\eta(x,y)),
\end{equation}
where $F$ and $G$ are arbitrary functions. Apply boundary conditions to solve for $\phi$.


\subsection{Parabolic PDEs ($\Delta = 0$)}
In this case, the characteristic equations~(\ref{eq:second_char}) reduce to a single equation
\begin{equation}
    \frac{dy}{dx} = \frac{B}{2A} \nonumber
\end{equation}
with solution given by:
\begin{equation}
    \xi(x,y) = \text{const.} \nonumber
\end{equation}
We are free to choose $\eta$.\\
Solve for boundary conditions.

\subsection{Elliptic PDEs ($\Delta<0$)}
Two families of complex characteristics are given by
\begin{equation}
    \frac{dy}{dx} = \frac{1}{2A}\left\{ B\pm i\sqrt{4AC-B^2} \right\} \nonumber
\end{equation}
with solutions given by 
\begin{equation}
    \xi(x,y)=\alpha,\quad \eta(x,y) = \beta
\end{equation}
$\alpha,\,\beta$ constant. \\
\textbf{Note:} $\xi(x,y)$ and $\eta(x,y)$ are complex conjugates of each other.\\
Introduce two new real variables $\lambda$ and $\mu$ defined by
\begin{align}
    \lambda = \xi +\eta,\quad \mu = i(\xi - \eta), \nonumber \\
    \xi = \frac{1}{2}(\lambda - i\mu),\quad \eta = \frac{1}{2}(\lambda + i\mu). \nonumber
\end{align}
Then
\begin{align}
    \frac{\partial}{\partial \xi} = \frac{\partial}{\partial \lambda}+i\frac{\partial}{\partial \mu},\quad \frac{\partial}{\partial \eta} = \frac{\partial}{\partial \lambda}+-\frac{\partial}{\partial \mu}, \nonumber \\
    \frac{\partial^2}{\partial\xi\partial\eta} = \frac{\partial^2}{\partial \lambda^2}+ \frac{\partial^2}{\partial mu^2}. \nonumber
\end{align}

\section{The method of separation of variables}
The main idea is to create a separable solution for, say y, such that:
\begin{equation}
    y(x,t) = X(x)T(t) \nonumber
\end{equation}
to then define
\begin{equation}
    y_{xx} = X^{\prime\prime} (x)T(t),quad y_{tt} = X(x)T^{\prime\prime}(t),
\end{equation}
to then make each side equal to a constant and solve as such.\\
Use examples.






\end{document}
