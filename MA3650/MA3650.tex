\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{url,amsmath,graphicx,amssymb,booktabs}
\usepackage[top=1.5cm, bottom=1.5cm, left=2.5cm, right=2.5cm]{geometry}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}

\title{MA3650 - Numerical Methods for Differential Equations}
\author{Luke Dando}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\section{Revision of Taylor series and Newton's method}
\subsection{Lecture 1}
\subsubsection{Newton's method}
Let $x_0$ be an initial guess of a root to a function $f(x)$. Then
\begin{equation}
    x_{n+1} = x_n - \frac{f(x)}{f^\prime(x)},\quad n\geq0. \label{eq:newton}
\end{equation}

\subsection{Lecture 2}
\subsubsection{IVT: Intermediate Value Theorem}
\begin{theorem}
Let $f:[a,b]\to \mathbb{R}$ be a continuous function, then $f$ achieves all values of the interval $[f(a),f(b)]$.\\
As a corollary, if $f(a)\cdot f(b)<0$, then $f$ has a root on $(a,b)$ (in the interior of $[a,b]$).
\end{theorem}
\subsubsection{Complex convergence}
\begin{lemma}
    The map $g:(0,\infty)\to\mathbb{R},\,g(x) = ln(e/x)$, maps $(e,\infty)$ into $(-\infty, 0)$ and $(0, e)$
to $(0, e)$.
\end{lemma}
\begin{corollary}
    Newton's method for $f(x) = ln(x)$ is possible for for any $x_0\in(0,e)$, and impossible when $x_0>e$.
\end{corollary}

\section{Convergence of Newton's method}
\subsection{Lecture 3}
\subsubsection{Babylonian iteration}
Let $\alpha>0$. To get an approximate value for $\sqrt{\alpha}$, start with a crude guess $x_1$ and improve on the approximation using
\begin{equation}
    x_{n+1} = \frac{(x_n+\alpha/x_n)}{2},\quad n\geq1. \label{eq:bab}
\end{equation}
\subsubsection{Error estimates}
\begin{lemma}
    Let $x_n$ be given by eq.~(\ref{eq:bab}). Then,
    \begin{equation}
        x_{n+1}-\sqrt{\alpha}=(x_n-\sqrt{\alpha})^2/2x_n. \label{eq:error1}
    \end{equation}
\end{lemma}
\subsubsection{Convergence close to the square root}
When $x_n\approx \sqrt{\alpha}$,
\begin{equation}
    (x_{n+1}-\sqrt{\alpha}) = \frac{(x_{n}-\sqrt{\alpha})^2}{2x_n} \approx \frac{(x_{n}-\sqrt{\alpha})^2}{2\sqrt{\alpha}}
\end{equation}
We define the error $e_n$ (at iterate $n$ as
\begin{equation}
    e_n = x_n - \sqrt{\alpha},
\end{equation}
allowing us to rewrite the estimate eq.~(\ref{eq:error1}) as
\begin{equation}
    e_{n+1} \approx \frac{e_n^2}{2\sqrt{\alpha}}
\end{equation}

\subsection{Lecture 4}
\subsubsection{Newton's method theory}
\begin{theorem}
    Let $I=[a,b]$ and $f:I\to\mathbb{R}$ be twice continuously differentiable. Suppose that
    \begin{equation}
        f(a)\cdot f(b)<0 \nonumber
    \end{equation}
    and that there are constants m and M, such that
    \begin{equation}
        0<m\leq \vert f^\prime(x)\vert\quad and \quad \vert f^{\prime\prime}(x)\vert \leq M
    \end{equation}
    for all $x\in I$. Let $K=M/2m$. Then, choose a root $r$ of $f$ in $I$ and $0<\delta<1/K$ such that $J=[r-\delta,r+\delta]\subseteq I$. Then, for any $x_0\in J$, the sequence defined by Newton's method in eq.~(\ref{eq:newton}) belongs to $J$ and ${x_n}_{n=1}^\infty$ converges to $r$. Moreover
    \begin{equation}
        \vert x_{n+1}-r\vert \leq K\vert x_n-r\vert^2,\quad n\geq0,
    \end{equation}
    so the convergence is quadratic.
\end{theorem}


\section{Wrapping up chapter 1}
\subsection{Lecture 6}
\subsection{Summary}


\section{Finite differences}
\subsection{Lecture 7}
\subsection{Lecture 8}


\section{Explicit numerical schemes for the heat equation}
\subsection{Lecture 9}
\subsection{Lecture 10}


\section{Further numerical schemes for the heat equation}
\subsection{Lecture 11}
\subsection{Lecture 12}


\section{Numerical schemes for complex boundary conditions}
\subsection{Lecture 13}


\section{Numerical schemes for complex boundary conditions 2}
\subsection{Lecture 14}
\subsection{Lecture 15}
\subsection{Lecture 16}


\section{Matrix norms}
\subsection{Lecture 17}


\section{Matrix perturbations and condition numbers}
\subsection{Lecture 18}
\subsection{Lecture 19}


\section{Interpolation, Lagrange polynomials}
\subsection{Lecture 21}
\subsection{Lecture 22}


\section{Interpolation, splines}
\subsection{Lecture 23}
\subsection{Lecture 24}


\section{Different schemes for the heat equation, consistency}
\subsection{Lecture 25}


\section{Consistency}
\subsection{Lecture 26}


\section{Convergence}
\subsection{Lecture 27}
\subsection{Lecture 28}


\section{Stability Fourier method}
\subsection{Lecture 29}
\subsection{Lecture 30}
\subsection{Lecture 31}


\section{Stability matrix method}
\subsection{Lecture 32}
\subsection{Lecture 33}
\subsection{Lecture 34}


\section{Polynomial Interpolation}
\subsection{Lagrange Polynomial}
For the Lagrange polynomials, $y_i$ and $f(x_i)$ can be used interchangeably.
Given $n+1$ points $(x_i,y_i) \in \mathbb{R}^2,\,0\leq i\leq n$, with $x_i\neq x_j$ when $i\neq j$. The polynomials
\begin{equation}
    L_i(x) = \prod_{j=0,\,\neq i}^n \left(\frac{x-x_j}{x_i-x_j}\right),\quad 0\leq i \leq n,
\end{equation}
satisfy $L_i(x_i)=1$ and $L_i(x_j)=0$ for $j\neq i$.
Now, given $n+1$ points $(x_i,y_i) \in \mathbb{R}^2,\,0\leq i\leq n$, with $x_i\neq x_j$ when $i\neq j$. The Lagrange polynomial $p$ is a polynomial of degree up to $n$ equal to
\begin{equation}
    p(x) = \sum_{i=0}^n y_iL_i(x).
\end{equation}
This is \textit{linear} if $n=1$ and \textit{quadratic} if $n=2$.
\subsection{Vandermonde Method}
Given $p(x)=ax^2+bx+c$, with $a,\,b$ and $c$ to be determined from the conditions $p(x_i)=y_i,\, i=0,\,1,\,2$, we can input this into a matrix know as the Vandermonde matrix and solve it for values $a,\,b$ and $c$.
\begin{equation}
    \begin{pmatrix}  x_0^2 & x_0 & 1 \\ x_1^2 & x_1 & 1 \\ x_2^2 & x_2 & 1 \end{pmatrix}\begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} y_0 \\ y_1 \\ y_2 \end{pmatrix}.
\end{equation}
This can be extended for larger polynomials trivially.

\end{document}
